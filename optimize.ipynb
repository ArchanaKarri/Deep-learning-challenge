{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                       0\n",
       "NAME                      0\n",
       "APPLICATION_TYPE          0\n",
       "AFFILIATION               0\n",
       "CLASSIFICATION            0\n",
       "USE_CASE                  0\n",
       "ORGANIZATION              0\n",
       "STATUS                    0\n",
       "INCOME_AMT                0\n",
       "SPECIAL_CONSIDERATIONS    0\n",
       "ASK_AMT                   0\n",
       "IS_SUCCESSFUL             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    NAME APPLICATION_TYPE  \\\n",
       "0                           BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1                 AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2                     ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3                         SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4               GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "...                                                  ...              ...   \n",
       "34294              THE LIONS CLUB OF HONOLULU KAMEHAMEHA               T4   \n",
       "34295           INTERNATIONAL ASSOCIATION OF LIONS CLUBS               T4   \n",
       "34296                                PTA HAWAII CONGRESS               T3   \n",
       "34297  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...               T5   \n",
       "34298                           WATERHOUSE CHARITABLE TR               T3   \n",
       "\n",
       "            AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0           Independent          C1000    ProductDev   Association       1   \n",
       "1           Independent          C2000  Preservation  Co-operative       1   \n",
       "2      CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3      CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4           Independent          C1000     Heathcare         Trust       1   \n",
       "...                 ...            ...           ...           ...     ...   \n",
       "34294       Independent          C1000    ProductDev   Association       1   \n",
       "34295  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "34296  CompanySponsored          C2000  Preservation   Association       1   \n",
       "34297       Independent          C3000    ProductDev   Association       1   \n",
       "34298       Independent          C1000  Preservation  Co-operative       1   \n",
       "\n",
       "          INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  IS_SUCCESSFUL  \n",
       "0                  0                      N      5000              1  \n",
       "1             1-9999                      N    108590              1  \n",
       "2                  0                      N      5000              0  \n",
       "3        10000-24999                      N      6692              1  \n",
       "4      100000-499999                      N    142590              1  \n",
       "...              ...                    ...       ...            ...  \n",
       "34294              0                      N      5000              0  \n",
       "34295              0                      N      5000              0  \n",
       "34296              0                      N      5000              0  \n",
       "34297              0                      N      5000              1  \n",
       "34298          1M-5M                      N  36500179              0  \n",
       "\n",
       "[34299 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(columns = ['EIN'], inplace=True)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "STATUS                        2\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "ASK_AMT                    8747\n",
       "IS_SUCCESSFUL                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column\n",
    "app_cat = application_df.dtypes.index.tolist()\n",
    "application_df[app_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_type_count = application_df['APPLICATION_TYPE'].value_counts()\n",
    "app_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Other      804\n",
       "T8         737\n",
       "T7         725\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(app_type_count[app_type_count < 600].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_count = application_df['CLASSIFICATION'].value_counts()\n",
    "class_count.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(class_count[class_count < 300].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>NAME_1 DAY RANCH RESCUE AND RURAL OKLAHOMA ANIMAL RESOURCE INC</th>\n",
       "      <th>NAME_100 BLACK MEN OF AMERICA</th>\n",
       "      <th>NAME_100 BLACK MEN OF MEMPHIS INC</th>\n",
       "      <th>NAME_100 BLACK MEN OF WEST GEORGIA INC</th>\n",
       "      <th>NAME_1150 WEBSTER STREET INC</th>\n",
       "      <th>NAME_116TH CAVALRY REGIMENT CHAPTER OF THE US CAVALRY &amp; ARMOR ASSOCIATION</th>\n",
       "      <th>NAME_13TH BOMB SQUADRON ASSOCIATION</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 19612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  \\\n",
       "0           1      5000              1   \n",
       "1           1    108590              1   \n",
       "2           1      5000              0   \n",
       "3           1      6692              1   \n",
       "4           1    142590              1   \n",
       "...       ...       ...            ...   \n",
       "34294       1      5000              0   \n",
       "34295       1      5000              0   \n",
       "34296       1      5000              0   \n",
       "34297       1      5000              1   \n",
       "34298       1  36500179              0   \n",
       "\n",
       "       NAME_1 DAY RANCH RESCUE AND RURAL OKLAHOMA ANIMAL RESOURCE INC  \\\n",
       "0                                                      0                \n",
       "1                                                      0                \n",
       "2                                                      0                \n",
       "3                                                      0                \n",
       "4                                                      0                \n",
       "...                                                  ...                \n",
       "34294                                                  0                \n",
       "34295                                                  0                \n",
       "34296                                                  0                \n",
       "34297                                                  0                \n",
       "34298                                                  0                \n",
       "\n",
       "       NAME_100 BLACK MEN OF AMERICA  NAME_100 BLACK MEN OF MEMPHIS INC  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "...                              ...                                ...   \n",
       "34294                              0                                  0   \n",
       "34295                              0                                  0   \n",
       "34296                              0                                  0   \n",
       "34297                              0                                  0   \n",
       "34298                              0                                  0   \n",
       "\n",
       "       NAME_100 BLACK MEN OF WEST GEORGIA INC  NAME_1150 WEBSTER STREET INC  \\\n",
       "0                                           0                             0   \n",
       "1                                           0                             0   \n",
       "2                                           0                             0   \n",
       "3                                           0                             0   \n",
       "4                                           0                             0   \n",
       "...                                       ...                           ...   \n",
       "34294                                       0                             0   \n",
       "34295                                       0                             0   \n",
       "34296                                       0                             0   \n",
       "34297                                       0                             0   \n",
       "34298                                       0                             0   \n",
       "\n",
       "       NAME_116TH CAVALRY REGIMENT CHAPTER OF THE US CAVALRY & ARMOR ASSOCIATION  \\\n",
       "0                                                      0                           \n",
       "1                                                      0                           \n",
       "2                                                      0                           \n",
       "3                                                      0                           \n",
       "4                                                      0                           \n",
       "...                                                  ...                           \n",
       "34294                                                  0                           \n",
       "34295                                                  0                           \n",
       "34296                                                  0                           \n",
       "34297                                                  0                           \n",
       "34298                                                  0                           \n",
       "\n",
       "       NAME_13TH BOMB SQUADRON ASSOCIATION  ...  INCOME_AMT_1-9999  \\\n",
       "0                                        0  ...                  0   \n",
       "1                                        0  ...                  1   \n",
       "2                                        0  ...                  0   \n",
       "3                                        0  ...                  0   \n",
       "4                                        0  ...                  0   \n",
       "...                                    ...  ...                ...   \n",
       "34294                                    0  ...                  0   \n",
       "34295                                    0  ...                  0   \n",
       "34296                                    0  ...                  0   \n",
       "34297                                    0  ...                  0   \n",
       "34298                                    0  ...                  0   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                           0                         0                   0   \n",
       "1                           0                         0                   0   \n",
       "2                           0                         0                   0   \n",
       "3                           1                         0                   0   \n",
       "4                           0                         1                   0   \n",
       "...                       ...                       ...                 ...   \n",
       "34294                       0                         0                   0   \n",
       "34295                       0                         0                   0   \n",
       "34296                       0                         0                   0   \n",
       "34297                       0                         0                   0   \n",
       "34298                       0                         0                   0   \n",
       "\n",
       "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                     0                       0                0   \n",
       "1                     0                       0                0   \n",
       "2                     0                       0                0   \n",
       "3                     0                       0                0   \n",
       "4                     0                       0                0   \n",
       "...                 ...                     ...              ...   \n",
       "34294                 0                       0                0   \n",
       "34295                 0                       0                0   \n",
       "34296                 0                       0                0   \n",
       "34297                 0                       0                0   \n",
       "34298                 1                       0                0   \n",
       "\n",
       "       INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                      0                         1                         0  \n",
       "1                      0                         1                         0  \n",
       "2                      0                         1                         0  \n",
       "3                      0                         1                         0  \n",
       "4                      0                         1                         0  \n",
       "...                  ...                       ...                       ...  \n",
       "34294                  0                         1                         0  \n",
       "34295                  0                         1                         0  \n",
       "34296                  0                         1                         0  \n",
       "34297                  0                         1                         0  \n",
       "34298                  0                         1                         0  \n",
       "\n",
       "[34299 rows x 19612 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "numeric_app_df = pd.get_dummies(application_df)\n",
    "numeric_app_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = numeric_app_df[\"IS_SUCCESSFUL\"]\n",
    "X = numeric_app_df.drop([\"IS_SUCCESSFUL\"],axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile, Train and Evaluate the Model\n",
    "Attempt #1\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 9)                 176508    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 18)                180       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,707\n",
      "Trainable params: 176,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 9\n",
    "hidden_nodes_layer2 = 18\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 7s 6ms/step - loss: 0.5210 - accuracy: 0.7381\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.2672 - accuracy: 0.8857\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1348 - accuracy: 0.9457\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1083 - accuracy: 0.9544\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1019 - accuracy: 0.9568\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0999 - accuracy: 0.9572\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0972 - accuracy: 0.9581\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0962 - accuracy: 0.9584\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0954 - accuracy: 0.9592\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0937 - accuracy: 0.9586\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0932 - accuracy: 0.9602\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0929 - accuracy: 0.9603\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0922 - accuracy: 0.9607\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0917 - accuracy: 0.9611\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0918 - accuracy: 0.9613\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0900 - accuracy: 0.9617\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0902 - accuracy: 0.9613\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0902 - accuracy: 0.9622\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0893 - accuracy: 0.9624\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0892 - accuracy: 0.9626\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0888 - accuracy: 0.9633\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0886 - accuracy: 0.9627\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0885 - accuracy: 0.9627\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0884 - accuracy: 0.9634\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0881 - accuracy: 0.9635\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9635\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0874 - accuracy: 0.9632\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0872 - accuracy: 0.9635\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0871 - accuracy: 0.9635\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0868 - accuracy: 0.9639\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0866 - accuracy: 0.9637\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0862 - accuracy: 0.9644\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0861 - accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0858 - accuracy: 0.9644\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0855 - accuracy: 0.9642\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0852 - accuracy: 0.9642\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0857 - accuracy: 0.9642\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0852 - accuracy: 0.9644\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0846 - accuracy: 0.9646\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0848 - accuracy: 0.9651\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0843 - accuracy: 0.9653\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0838 - accuracy: 0.9653\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9654\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9658\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9658\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0829 - accuracy: 0.9655\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0827 - accuracy: 0.9655\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0826 - accuracy: 0.9659\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0834 - accuracy: 0.9651\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0827 - accuracy: 0.9659\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0821 - accuracy: 0.9659\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0816 - accuracy: 0.9656\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0817 - accuracy: 0.9660\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0817 - accuracy: 0.9660\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0816 - accuracy: 0.9663\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0815 - accuracy: 0.9661\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0813 - accuracy: 0.9662\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0812 - accuracy: 0.9659\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0814 - accuracy: 0.9663\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0814 - accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0813 - accuracy: 0.9659\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0811 - accuracy: 0.9661\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0809 - accuracy: 0.9664\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0807 - accuracy: 0.9668\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0807 - accuracy: 0.9673\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0806 - accuracy: 0.9666\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0808 - accuracy: 0.9665\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0804 - accuracy: 0.9668\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0807 - accuracy: 0.9663\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9670\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0804 - accuracy: 0.9663\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9669\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0806 - accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0804 - accuracy: 0.9668\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0803 - accuracy: 0.9671\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0802 - accuracy: 0.9671\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0806 - accuracy: 0.9668\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0801 - accuracy: 0.9669\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9668\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9667\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0802 - accuracy: 0.9665\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0802 - accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0796 - accuracy: 0.9672\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0797 - accuracy: 0.9675\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0797 - accuracy: 0.9670\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0796 - accuracy: 0.9672\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0798 - accuracy: 0.9664\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0799 - accuracy: 0.9668\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0797 - accuracy: 0.9670\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0796 - accuracy: 0.9669\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0795 - accuracy: 0.9673\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0795 - accuracy: 0.9668\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0793 - accuracy: 0.9670\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0797 - accuracy: 0.9669\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0796 - accuracy: 0.9673\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0793 - accuracy: 0.9670\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0791 - accuracy: 0.9672\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0793 - accuracy: 0.9673\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0791 - accuracy: 0.9675\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0794 - accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 5s - loss: 0.5759 - accuracy: 0.7264 - 5s/epoch - 18ms/step\n",
      "Loss: 0.5758815407752991, Accuracy: 0.7264139652252197\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy\n",
    "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('Models/AlphabetSoupCharity1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "This is Attempt #1\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "\n",
    "Loss: 0.5758815407752991, Accuracy: 0.7264139652252197\n",
    "\n",
    "A loss value of 57 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "I need to make some changes in order to get to 75% accuracy.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "\n",
    "Loss: 0.5522796763553564, Accuracy: 0.7250145673751831\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "\n",
    "Loss: 0.5575985619278065, Accuracy: 0.7231487035751343"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt #2 -- adding a hidden layer\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "layer3 = 27 : activation function = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 9)                 176508    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 18)                180       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 27)                513       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,229\n",
      "Trainable params: 177,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 9\n",
    "hidden_nodes_layer2 = 18\n",
    "hidden_nodes_layer3 = 27\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.4920 - accuracy: 0.7674\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.3154 - accuracy: 0.8575\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1621 - accuracy: 0.9386\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1145 - accuracy: 0.9556\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.1015 - accuracy: 0.9612\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0988 - accuracy: 0.9611\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0970 - accuracy: 0.9619\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0960 - accuracy: 0.9621\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0946 - accuracy: 0.9623\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9626\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0933 - accuracy: 0.9626\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0934 - accuracy: 0.9631\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0937 - accuracy: 0.9624\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0928 - accuracy: 0.9631\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0920 - accuracy: 0.9632\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0925 - accuracy: 0.9630\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0919 - accuracy: 0.9637\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0913 - accuracy: 0.9635\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0914 - accuracy: 0.9637\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0916 - accuracy: 0.9637\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0914 - accuracy: 0.9630\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0914 - accuracy: 0.9637\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0904 - accuracy: 0.9640\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0904 - accuracy: 0.9638\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0941 - accuracy: 0.9635\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0929 - accuracy: 0.9635\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0911 - accuracy: 0.9634\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0905 - accuracy: 0.9638\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0901 - accuracy: 0.9637\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0894 - accuracy: 0.9644\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0890 - accuracy: 0.9643\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0891 - accuracy: 0.9642\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0882 - accuracy: 0.9640\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0885 - accuracy: 0.9641\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0882 - accuracy: 0.9639\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.0884 - accuracy: 0.9634\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 6s 7ms/step - loss: 0.0878 - accuracy: 0.9643\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0877 - accuracy: 0.9641\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.9642\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0870 - accuracy: 0.9652\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0870 - accuracy: 0.9647\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0871 - accuracy: 0.9645\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9646\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0867 - accuracy: 0.9649\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0866 - accuracy: 0.9651\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9650\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0873 - accuracy: 0.9645\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0867 - accuracy: 0.9651\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0863 - accuracy: 0.9652\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.9654\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.9647\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.9652\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0854 - accuracy: 0.9651\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0856 - accuracy: 0.9649\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.9656\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0854 - accuracy: 0.9654\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0852 - accuracy: 0.9654\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0852 - accuracy: 0.9654\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0848 - accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0850 - accuracy: 0.9656\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0851 - accuracy: 0.9654\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0847 - accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0849 - accuracy: 0.9654\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0846 - accuracy: 0.9659\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0845 - accuracy: 0.9658\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0847 - accuracy: 0.9656\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0843 - accuracy: 0.9659\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0843 - accuracy: 0.9655\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0843 - accuracy: 0.9657\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0841 - accuracy: 0.9658\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.9658\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.9658\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.9656\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0839 - accuracy: 0.9657\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0839 - accuracy: 0.9658\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0838 - accuracy: 0.9655\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9661\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0836 - accuracy: 0.9661\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.9660\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0838 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.9661\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0834 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.9659\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9665\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.9659\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9663\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9663\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0832 - accuracy: 0.9665\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.9665\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.9664\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0832 - accuracy: 0.9660\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0836 - accuracy: 0.9662\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0829 - accuracy: 0.9664\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0829 - accuracy: 0.9659\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0825 - accuracy: 0.9665\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0829 - accuracy: 0.9665\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0822 - accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.6051 - accuracy: 0.7290 - 616ms/epoch - 2ms/step\n",
      "Loss: 0.6051175594329834, Accuracy: 0.7289795875549316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAn30lEQVR4nO3dfZBc1X3n//dnuuf5QRrBSNYTSMYKSMZIgKJ17F0vjtYY+xdbhloqYhOCVTiYLcjam2RjzMa1Tjm7Szkm+SWBn1XyhoAT21RizM+yizUG4oTKFjESIB70ZIQk0CAhjR5Ho5me6Yfv/tF3htaopemRRkjM/byqprrvvefcPmc0Ot97zrm3jyICMzNLn7pzXQAzMzs3HADMzFLKAcDMLKUcAMzMUsoBwMwspRwAzMxSqqYAIOk6SVslbZN0V5XjnZIelfSSpGclXZ7sv1TShoqfXklfTI59VdKbFcc+OaE1MzOzU9JYzwFIygC/AD4GdAPrgJsiYlNFmj8B+iLijyRdBtwfEcurnOdN4F9FxOuSvprk+cZEVsjMzGqTrSHNMmBbRGwHkPQwsALYVJFmEfA/ASJii6R5kmZExN6KNMuB1yLi9dMt7IUXXhjz5s073exmZqn03HPP7Y+IrtH7awkAs4FdFdvdwL8aleZF4AbgnyUtAy4G5gCVAWAl8L1R+e6U9FvAeuD3IuLQqQoyb9481q9fX0ORzcxsmKSqF961zAGoyr7R40b3AJ2SNgC/A7wAFCo+vAH4NPD3FXm+CVwCLAH2APeepOC3SVovaX1PT08NxTUzs1rU0gPoBuZWbM8BdlcmiIheYBWAJAE7kp9hnwCerxwSqnwv6VvAj6t9eESsAdYALF261F9cZGY2QWrpAawDFkian1zJrwTWViaQNDU5BvA54OkkKAy7iVHDP5JmVmxeD7wy3sKbmdnpG7MHEBEFSXcCjwMZ4IGI2Cjp9uT4amAh8G1JRcqTw7cO55fUQvkOos+POvXXJS2hPJy0s8pxMzM7i8a8DfR8snTp0vAksJnZ+Eh6LiKWjt7vJ4HNzFLKAcDMLKVquQvIzOycGR6mLt9geHr5T5a3VAq27z/Gtn19zJraxILp7TQ3ZAA4msuz+3COYiloyNbRkKkjVyjSO5CnN5cnX3x7+FxApk7U1YkpzfVcPK2Faa0NI59bLAVHc3l6Bwr05vIAzL+wldbGchOcyxfZuLuX1/b1UUrqW4ry/oF8kcF8kRuumsO8C1tP63dwMg4A9q5XKJYolIKm+sw79pnFUnBsqMDAUJHOlgYasm93pkul4Bf7jpKRuKSrjbq6txufiGCoWKIhU1e1Udp3NMe6HYfYsb+PqS0NXNjWwNSWBiLKn1mKoE4iUzf8A5m6OgQcPDbE3t4c+/sGacxmmNpSz5TmevYcybFpdy9b3uqlpSHLolkdLJzZQSmCbfv6eHXvUY4NFmlqyNCUraOtMUtnawOdLfUAvHl4gO5DAxwbLDDvglbe29XKjI4m+gYL9A4UOJrLM5AvksuXGCqWRhpDCQrFIF8skS8GHU1ZprY0MDU571ChRL5YeruRK5Robcwyvb2R6e1N7O3N8WL3YV7cdZjDA3nqM3U0Zuqoz9ZRnxH1mTo6Wxp43/Q23je9jZaGDFv2HGXTnl7eONjPYKFIvhgUSzGSvjFbR3tTPR3NWeozdby6t4++wZFHlpBgTmczvQMFjgzkz+hvpL0xS3tTlt5c4bjPqDR7ajMdzfW8uvcohdLJ52MluOrizgkPAJ4EtjMWEbxxsJ/Xevpoqs/Q1pilpSFLY7aO+kwdDdk6WhoyNGarN3qnsvvwAP1DRTqas3Q01VMnJY1NkQ27DvP4xrf4hy37ODKQZ9aUZt7b1crcaS1c2NZIV1sDLQ1Z+ocK9A0WOTKQZ9/RHPt6B9nfN0jfYIFjgwUKxeDiC1t4X1cbF01rYf+xIboPDbCvN0dXeyOXdLUxp7OZPUdybNx9hC1vHeVw/9uNQ0Omjkvf087lszs4eGyIn+84OHJ8aks9Sy+eRkdzlm37+nhtXx/HhopI0JTN0NKQoaUxQ2tDloF8kdcP9E/ov82waa0NLJzZTt9gkS17ehkslEbK/t6uVqa21JPLlxvjo7kCh/uHODZUBODCtkbmdDbTVF/H6wf62XMkd9y5m+vL9Wiqz9CQrSMiKEZQKkF9RjRk66iTTjhvnaA+U0dTfYbm+gyN9XX05QocODYElBu9X5rezpK5U5nR0chQEkyGCqWR4NHTN8hr+/rYnZRpWmsD75/VwfwLW2muz1CfqaOuThSKw8GmlASuctBaML2Ny2dPYcGMdvYcHmDLW0fZvv8YU5qzzOlsYdbUZhoyYrBQDmLN9Rnam8oNe2XQHw7QxQgOHRvi9QP9vH7gGH2DRaY0lwNOe1M5IHc0ZSlF8FrPMV7de5SD/XneP6uDJXOnsvA9HdRny/9HhGiqL/9+Tuf/TqWTTQI7AJwnSqXyleFQsfwfs60hS12dki5qHxt2HWHH/j6ashlaG7M01tdxLLkCG766yNaJ+mwdl3S1ccWcKVzS1UbP0UFe6j7Mxt297DrYz+4jA+ztHUSCjqZ6OprrubCtgVlTmpk5tYnWhuzIH7JgpOvbN1jgjYP9vH6gnyMDeVqTRqt/qMi6nQfZd3RwzDpm60RLQ4ZI6lsKaG3MjJTjomktvG96G/MubGXLnl6e2ryPrXuPnvKcHU1Z/t3CGcyd1sLOA8fYsf8Y3YcGONQ/xOg/7fqMmN7exPSORi5sa6S9MUtrY5Y6wY4D/by2r483Dw8wrbWBOZ3NTG9vZG/vINt7yo12U30dl72ng0WzOpje3khrQ5bmhgy7DvXzyptHeOXNXtqbsvzKey/gg++9gGIE63YcZN3Og+TypZEr1a72RnJJEDs2VKR/sBygsnXiqoun8svzpnHZezo4msvT0zfIkf48Sq7661QeGiiWYuTfqZT0DDpbG5jeXq7bULHE4WN5DvUPMaOjiRkdjSMNSKFYYueBY2Tq6pjb2Uw2U30qcLBQJIITelb9QwX2Hx0aaQhPlv9k8sXSSC+mmqFCif19g3Q019PWWNsgRd9ggf7BAl3tjWfUUE5WDgBnwVChNHIV2TdYYN/RQfYcHmD3kRyDhfJVDgE9Rwd5bf8xdvT00Vif4eqLOrn64k4asnU89/ohnnv9EG8eHjju3FK5C1keanj7iml0L7FOjIwjDgeR4bHJbJ1GupV1gplTmpk5pYn3TGkCoDdX7ub29ObYe3SQ4im6oMPnmDW1mWmtDfQPFTk2WCCbEVdd1MnSedNYNLODoUKJY4MFjg0VyBeDoUKJwUKR/qEifYPlIZPhsklwbKg8pnq4P8/OA+XGG8pDCMvmTWP5wul0tTfSmytftUG5QWqqr2PeBa0smz+N+ioNUKFY4lB/nv6hAi0NWdoaszTVj30VVSiWTmjQIoJD/XmmNNeftNEyO5+dLAB4DuAk9hwZICONNK7P7jjI06/28C/bD3Kgb5DeXJ5cvlQ1r1TuWg+b1trAe7ta+fSSWRwbLPLc64f4yca3AJjR0cjSi6fx76+eQ2N93Ui+8kRTgYjg8tlTWDJ3Kpd0tVEoBf1DBXL5Em1NWVobMsc1asVSsGN/Hy91H2HrW0eZOaWJD8yZyqKZHSOTW9UUku70wFAxudIsn3Mo6XI31WeYPbX5uG7v2dA/VGDn/n5mT21mSjJWfDqymTq62huBxnHnG00S01obqqQ2e3dzAKjif7+8h//4nedP2N+YrWPZ/GksmTuFjqZ62pvKV5atyU9XeyMzpzQxo6Op6lVppX1HcxSKwcwpTePqsjbUiYbsyRujTJ143/R23je9veZzQrnhmzmleVx5zobhSUozO/scAEYZLBT5H/97M780o43f+pV5HBssMFQoseSi8tjsRN1pMr29aULOY2Z2uhwARvmbZ15n18EB/ubWZfybBSesn2BmNmn4SeAKh/uH+IunXuUjv9Tlxt/MJj0HgAr3/cM2+gYL3P3Jy851UczMzjoHgMSug/089MxObrx6Lpe9x5OQZjb5OQAkfrppL/li8DvL33eui2Jm9o5wAEhs3tObPPLecq6LYmb2jqgpAEi6TtJWSdsk3VXleKekRyW9JOlZSZdXHNsp6WVJGyStr9g/TdITkl5NXjsnpkqnZ8tbvSycOb57583M3s3GDACSMsD9lBd2XwTcJGnRqGR3Axsi4grgt4A/H3X8oxGxZNSjyHcBT0XEAuCpZPucKBRL/GJvHwtneuzfzNKjlh7AMmBbRGyPiCHgYWDFqDSLKDfiRMQWYJ6kGWOcdwXwUPL+IeAztRZ6ou3Yf4yhQsk9ADNLlVoCwGxgV8V2d7Kv0ovADQCSlgEXA3OSYwH8VNJzkm6ryDMjIvYAJK/Tx1/8ibFpTy+A7/4xs1Sp5Ungal9UM/prI+8B/lzSBuBl4AVgeAWED0fEbknTgSckbYmIp2stYBI0bgO46KKLas02Lpv3HKU+U168w8wsLWrpAXQDcyu25wC7KxNERG9ErIqIJZTnALqAHcmx3cnrPuBRykNKAHslzQRIXvdV+/CIWBMRSyNiaVfX2Xk6d8tbvVzS1XbWv+nSzOx8UkuLtw5YIGm+pAZgJbC2MoGkqckxgM8BT0dEr6RWSe1JmlbgWuCVJN1a4Jbk/S3AD8+sKqdv855eFnkC2MxSZswhoIgoSLoTeBzIAA9ExEZJtyfHVwMLgW9LKgKbgFuT7DOAR5OvO84C342InyTH7gH+TtKtwBvAjRNXrdqV11Ed9B1AZpY6NX0baEQ8Bjw2at/qivfPAAuq5NsOLD7JOQ8Ay8dT2LNhy/AEsO8AMrOUSf2g9/AdQO4BmFnapD4AbHnrKBe2lRfSNjNLk9QHgM17/BUQZpZOqQ4AhWKJV/f2+Q4gM0ulVAeA7fuPMVQseQLYzFIp1QFgsyeAzSzFUh0A9vbmALwGgJmlUqoDwMBQCYDm+sw5LomZ2Tsv3QEgX6QhW0emrtr33ZmZTW6pDgC5fJEmfwGcmaVUqlu/XL5Ic4OHf8wsnVIdAAbyRY//m1lqpTsADBVpcgAws5RKdwDIOwCYWXqlOgDkPARkZimW8gBQ8iSwmaVWTQFA0nWStkraJumuKsc7JT0q6SVJz0q6PNk/V9LPJG2WtFHSFyryfFXSm5I2JD+fnLhq1caTwGaWZmOuCCYpA9wPfIzyAvHrJK2NiE0Vye4GNkTE9ZIuS9IvBwrA70XE88nawM9JeqIi759FxDcmskLj4UlgM0uzWnoAy4BtEbE9IoaAh4EVo9IsAp4CiIgtwDxJMyJiT0Q8n+w/CmwGZk9Y6c9QLl+kqT7Vo2BmlmK1tH6zgV0V292c2Ii/CNwAIGkZcDEwpzKBpHnAlcDPK3bfmQwbPSCpc3xFP3OeBDazNKslAFT7opwYtX0P0ClpA/A7wAuUh3/KJ5DagEeAL0ZEb7L7m8AlwBJgD3Bv1Q+XbpO0XtL6np6eGopbm4gozwF4EtjMUmrMOQDKV/xzK7bnALsrEySN+ioASQJ2JD9Iqqfc+H8nIn5QkWfv8HtJ3wJ+XO3DI2INsAZg6dKlowPPaRsqligFngMws9SqpQewDlggab6kBmAlsLYygaSpyTGAzwFPR0RvEgz+CtgcEX86Ks/Mis3rgVdOtxKnI5d8FbQDgJml1Zg9gIgoSLoTeBzIAA9ExEZJtyfHVwMLgW9LKgKbgFuT7B8GbgZeToaHAO6OiMeAr0taQnk4aSfw+YmqVC0G8kXAawGYWXrVMgRE0mA/Nmrf6or3zwALquT7Z6rPIRARN4+rpBMsNxwAGnwXkJmlU2pbP/cAzCztUh8APAdgZmmV2gCQG3IAMLN0S20A8BCQmaVdagNALl++DdQPgplZWqU2ALgHYGZpl/oA0OgvgzOzlEpt6zc8CewegJmlVXoDgG8DNbOUS20AGMgXqc+I+kxqfwVmlnKpbf0G8l4NzMzSLbUBIOcAYGYpl9oAMDDk1cDMLN1SGwBy+ZIDgJmlWmoDwEC+SJOfAjazFEt3AMimtvpmZrUFAEnXSdoqaZuku6oc75T0qKSXJD0r6fKx8kqaJukJSa8mr50TU6Xa5LwgvJml3JgBQFIGuB/4BLAIuEnSolHJ7gY2RMQVwG8Bf15D3ruApyJiAfBUsv2O8SSwmaVdLT2AZcC2iNgeEUPAw8CKUWkWUW7EiYgtwDxJM8bIuwJ4KHn/EPCZM6nIeOUKDgBmlm61BIDZwK6K7e5kX6UXgRsAJC0DLgbmjJF3RkTsAUhep1f7cEm3SVovaX1PT08Nxa3NwFDJk8Bmlmq1BIBqi7rHqO17gE5JG4DfAV4ACjXmPaWIWBMRSyNiaVdX13iynlIuX6Qp6wBgZumVrSFNNzC3YnsOsLsyQUT0AqsAJAnYkfy0nCLvXkkzI2KPpJnAvtOqwWkayBdpbvBdQGaWXrW0gOuABZLmS2oAVgJrKxNImpocA/gc8HQSFE6Vdy1wS/L+FuCHZ1aV2uWLJYql8ByAmaXamD2AiChIuhN4HMgAD0TERkm3J8dXAwuBb0sqApuAW0+VNzn1PcDfSboVeAO4cWKrdnID/ipoM7OahoCIiMeAx0btW13x/hlgQa15k/0HgOXjKexEGV4MxgHAzNIslYPgXg/YzCztAcC3gZpZiqUyAOTyJcA9ADNLt1QGgAHPAZiZpTMAvL0gfCqrb2YGpDQAeA7AzCylASDnu4DMzNIZAHwbqJlZWgNAMgnc6ABgZimWygDgISAzs5QGgIF8kUydqM9U+7ZqM7N0SGUAyOVLNNdnKH9ztZlZOqUyAAzki34IzMxSL5UBIDdU9ENgZpZ6qWwFB/JeEN7MrKYAIOk6SVslbZN0V5XjUyT9SNKLkjZKGl4e8lJJGyp+eiV9MTn2VUlvVhz75ITW7BTKy0E6AJhZuo25IIykDHA/8DHK6wOvk7Q2IjZVJLsD2BQRn5LUBWyV9J2I2AosqTjPm8CjFfn+LCK+MTFVqV3OcwBmZjX1AJYB2yJie0QMAQ8DK0alCaA9WRC+DTgIFEalWQ68FhGvn2GZz9hAvuQAYGapV0sAmA3sqtjuTvZVuo/yusC7gZeBL0REaVSalcD3Ru27U9JLkh6Q1Fl7sc9MbqhIsyeBzSzlamkFq90sH6O2Pw5sAGZRHvK5T1LHyAmkBuDTwN9X5PkmcEmSfg9wb9UPl26TtF7S+p6enhqKOzZPApuZ1RYAuoG5FdtzKF/pV1oF/CDKtgE7gMsqjn8CeD4i9g7viIi9EVFMegrfojzUdIKIWBMRSyNiaVdXVw3FHVvOk8BmZjUFgHXAAknzkyv5lcDaUWneoDzGj6QZwKXA9orjNzFq+EfSzIrN64FXxlf00+cHwczMargLKCIKku4EHgcywAMRsVHS7cnx1cDXgAclvUx5yOhLEbEfQFIL5TuIPj/q1F+XtITycNLOKsfPGt8FZGZWQwAAiIjHgMdG7Vtd8X43cO1J8vYDF1TZf/O4SjpB8sUS+WJ4DsDMUi91t8L4q6DNzMpSGADKd6c2eRLYzFIuhQGg3ANoyqau6mZmx0ldKziyHrB7AGaWcukLAEOeAzAzgzQGAE8Cm5kBKQwAI3MAHgIys5RLbwDIOgCYWbqlLgB4EtjMrCx9AWCo/ByA5wDMLO1SFwD8JLCZWVnqAsDwEFCjF4Qxs5RLXSuYyxeRoNFPAptZyqWuFczlizRlM5SXLzYzS68UBoASTR7+MTNLYwAo0uhnAMzMagsAkq6TtFXSNkl3VTk+RdKPJL0oaaOkVRXHdkp6WdIGSesr9k+T9ISkV5PXzomp0qkNFtwDMDODGgKApAxwP+WF3RcBN0laNCrZHcCmiFgMXAPcm6wfPOyjEbEkIpZW7LsLeCoiFgBPJdtnnZeDNDMrq+VSeBmwLSK2R8QQ8DCwYlSaANpVnlltAw4ChTHOuwJ4KHn/EPCZWgt9JnKFEo0OAGZmNQWA2cCuiu3uZF+l+4CFwG7gZeALEVFKjgXwU0nPSbqtIs+MiNgDkLxOP43yj1v5LiAPAZmZ1dISVrtfMkZtfxzYAMwClgD3SepIjn04Iq6iPIR0h6SPjKeAkm6TtF7S+p6envFkrWowX3QPwMyM2gJANzC3YnsO5Sv9SquAH0TZNmAHcBlAROxOXvcBj1IeUgLYK2kmQPK6r9qHR8SaiFgaEUu7urpqq9UpDBZK7gGYmVFbAFgHLJA0P5nYXQmsHZXmDWA5gKQZwKXAdkmtktqT/a3AtcArSZ61wC3J+1uAH55JRWrlSWAzs7LsWAkioiDpTuBxIAM8EBEbJd2eHF8NfA14UNLLlIeMvhQR+yW9F3g0eeo2C3w3In6SnPoe4O8k3Uo5gNw4wXWryg+CmZmVjRkAACLiMeCxUftWV7zfTfnqfnS+7cDik5zzAEmv4Z2UK7gHYGYGqX0SOHXVNjM7QapawohIngR2D8DMLFUBYKhYIgIHADMzUhYAcvnys2keAjIzS1kAGExWA3MPwMwsZQHAPQAzs7elqiUcLLgHYGY2LFUBYLgH4ABgZpa2ADDSA0hVtc3MqkpVS5jzJLCZ2YhUBYBBTwKbmY1IVUuY8ySwmdmIdAWA4UngrAOAmVnKAoAngc3MhqWqJRwOAF4S0swsZQFgsDD8HECqqm1mVlVNLaGk6yRtlbRN0l1Vjk+R9CNJL0raKGlVsn+upJ9J2pzs/0JFnq9KelPShuTnkxNXreoG80UkaMg4AJiZjbkimKQMcD/wMcoLxK+TtDYiNlUkuwPYFBGfktQFbJX0HaAA/F5EPJ+sDfycpCcq8v5ZRHxjQmt0CrlCicZsHckSlWZmqVbLpfAyYFtEbI+IIeBhYMWoNAG0q9yytgEHgUJE7ImI5wEi4iiwGZg9YaUfJy8Ib2b2tloCwGxgV8V2Nyc24vcBC4HdwMvAFyKiVJlA0jzgSuDnFbvvlPSSpAckdY6z7OOWyxd9C6iZWaKWAFBtvCRGbX8c2ADMApYA90nqGDmB1AY8AnwxInqT3d8ELknS7wHurfrh0m2S1kta39PTU0NxT668HKTH/83MoLYA0A3MrdieQ/lKv9Iq4AdRtg3YAVwGIKmecuP/nYj4wXCGiNgbEcWkp/AtykNNJ4iINRGxNCKWdnV11VqvqsoLwrsHYGYGtQWAdcACSfMlNQArgbWj0rwBLAeQNAO4FNiezAn8FbA5Iv60MoOkmRWb1wOvnF4VapfLuwdgZjZszLuAIqIg6U7gcSADPBARGyXdnhxfDXwNeFDSy5SHjL4UEfsl/WvgZuBlSRuSU94dEY8BX5e0hPJw0k7g8xNasypy+aIfAjMzS4wZAACSBvuxUftWV7zfDVxbJd8/U30OgYi4eVwlnQC5QokpzfXv9MeamZ2XUjUeMpgv0uSvgjYzA9IWAAolDwGZmSVSFQBy7gGYmY1IVWvoJ4HNzN6WsgDg20DNzIalpjWMCAYL7gGYmQ1LTQDIF4NSeEF4M7NhqWkNvSC8mdnx0hMAvBykmdlxUhMABvPJcpAeAjIzA9IUADwEZGZ2nNQEgFzSA/AksJlZWWpaw+E5APcAzMzKUhQAkjkABwAzMyBVAWC4B5CaKpuZnVJqWsPBgnsAZmaVagoAkq6TtFXSNkl3VTk+RdKPJL0oaaOkVWPllTRN0hOSXk1eOyemStWNPAfgSWAzM6CGACApA9wPfAJYBNwkadGoZHcAmyJiMXANcK+khjHy3gU8FRELgKeS7bPGTwKbmR2vlsvhZcC2iNgeEUPAw8CKUWkCaE8WgW8DDgKFMfKuAB5K3j8EfOZMKjKWkUngrAOAmRnUFgBmA7sqtruTfZXuAxYCu4GXgS9ERGmMvDMiYg9A8jp93KUfh+EHwRo9CWxmBtQWAKot6h6jtj8ObABmAUuA+yR11Jj31B8u3SZpvaT1PT0948l6HD8IZmZ2vFpaw25gbsX2HMpX+pVWAT+Ism3ADuCyMfLulTQTIHndV+3DI2JNRCyNiKVdXV01FLe6wXyRxmwd5VEqMzOrJQCsAxZImi+pAVgJrB2V5g1gOYCkGcClwPYx8q4Fbkne3wL88EwqMhYvB2lmdrzsWAkioiDpTuBxIAM8EBEbJd2eHF8NfA14UNLLlId9vhQR+wGq5U1OfQ/wd5JupRxAbpzYqh3Py0GamR1vzAAAEBGPAY+N2re64v1u4Npa8yb7D5D0Gt4JXg7SzOx4qbkkzuVLvgXUzKxCegJAoehbQM3MKqSmRczli+4BmJlVSFEAKLkHYGZWITUt4mCh5ElgM7MK6QkAfg7AzOw4qQkA5TmA1FTXzGxMqWkRcwXPAZiZVUpNi+i7gMzMjpeaAOBJYDOz46UiAOSLJYql8HcBmZlVSEWLOLwesHsAZmZvS0kA8GIwZmajpaJFHO4BNLoHYGY2oqavg363GywkC8I7AJid1/L5PN3d3eRyuXNdlHelpqYm5syZQ319fU3pUxEARuYAPARkdl7r7u6mvb2defPmefnWcYoIDhw4QHd3N/Pnz68pT00toqTrJG2VtE3SXVWO/xdJG5KfVyQVJU2TdGnF/g2SeiV9McnzVUlvVhz75HgqOx6DBU8Cm70b5HI5LrjgAjf+p0ESF1xwwbh6T2P2ACRlgPuBj1Fe5H2dpLURsWk4TUT8CfAnSfpPAf85Ig4CB4ElFed5E3i04vR/FhHfqLm0p8mTwGbvHm78T994f3e1tIjLgG0RsT0ihoCHgRWnSH8T8L0q+5cDr0XE6+Mq4QTwbaBmZieqJQDMBnZVbHcn+04gqQW4DnikyuGVnBgY7pT0kqQHJHWe5Jy3SVovaX1PT08NxT2RJ4HN7HxSKBTOdRGA2gJAtT5FnCTtp4D/kwz/vH0CqQH4NPD3Fbu/CVxCeYhoD3BvtRNGxJqIWBoRS7u6umoo7one7gF4CMjMTu0zn/kMV199Ne9///tZs2YNAD/5yU+46qqrWLx4McuXLwegr6+PVatW8YEPfIArrriCRx4pX/e2tbWNnOv73/8+n/3sZwH47Gc/y+/+7u/y0Y9+lC996Us8++yzfOhDH+LKK6/kQx/6EFu3bgWgWCzy+7//+yPn/cu//Eueeuoprr/++pHzPvHEE9xwww1nXNda7gLqBuZWbM8Bdp8kbbWrfIBPAM9HxN7hHZXvJX0L+HENZTktw3MA7gGYvXv80Y82sml374Sec9GsDv7bp95/yjQPPPAA06ZNY2BggF/+5V9mxYoV/PZv/zZPP/008+fP5+DB8vXt1772NaZMmcLLL78MwKFDh8b8/F/84hc8+eSTZDIZent7efrpp8lmszz55JPcfffdPPLII6xZs4YdO3bwwgsvkM1mOXjwIJ2dndxxxx309PTQ1dXFX//1X7Nq1aoz/n3UEgDWAQskzac8ibsS+A+jE0maAvxb4DernOOEeQFJMyNiT7J5PfDKOMo9LiMPgnkS2MzG8Bd/8Rc8+mj5XpVdu3axZs0aPvKRj4zcWjlt2jQAnnzySR5++OGRfJ2dVUexj3PjjTeSyZQvRI8cOcItt9zCq6++iiTy+fzIeW+//Xay2exxn3fzzTfzt3/7t6xatYpnnnmGb3/722dc1zEDQEQUJN0JPA5kgAciYqOk25Pjq5Ok1wM/jYhjlfmTeYGPAZ8fdeqvS1pCeThpZ5XjE8ZzAGbvPmNdqZ8N//iP/8iTTz7JM888Q0tLC9dccw2LFy8eGZ6pFBFV77qp3Df6lszW1taR91/5ylf46Ec/yqOPPsrOnTu55pprTnneVatW8alPfYqmpiZuvPHGkQBxJmq6JI6IxyLilyLikoj478m+1RWNPxHxYESsrJK3PyIuiIgjo/bfHBEfiIgrIuLTFb2BCecegJnV4siRI3R2dtLS0sKWLVv4l3/5FwYHB/mnf/onduzYATAyBHTttddy3333jeQdHgKaMWMGmzdvplQqjfQkTvZZs2eX76d58MEHR/Zfe+21rF69emSiePjzZs2axaxZs/jjP/7jkXmFM5WKFjFXKNKYrfP9xWZ2Stdddx2FQoErrriCr3zlK3zwgx+kq6uLNWvWcMMNN7B48WJ+/dd/HYA//MM/5NChQ1x++eUsXryYn/3sZwDcc889/Nqv/Rq/+qu/ysyZM0/6WX/wB3/Al7/8ZT784Q9TLBZH9n/uc5/joosu4oorrmDx4sV897vfHTn2G7/xG8ydO5dFixZNSH0VcbIbes4/S5cujfXr148731fXbuTRF97kxf927VkolZlNlM2bN7Nw4cJzXYzz1p133smVV17JrbfeetI01X6Hkp6LiKWj06biu4Aue087H3//jHNdDDOz03b11VfT2trKvfdWvWP+tKQiAKxcdhErl110rothZnbannvuuQk/ZyrmAMzM7EQOAGZ2Xnk3zUueb8b7u3MAMLPzRlNTEwcOHHAQOA3D6wE0NTXVnCcVcwBm9u4wZ84curu7Od0vfky74RXBauUAYGbnjfr6+ppXs7Iz5yEgM7OUcgAwM0spBwAzs5R6V30VhKQeYDxLSl4I7D9LxTmfpbHeaawzpLPeaawznFm9L46IE1bUelcFgPGStL7a919MdmmsdxrrDOmsdxrrDGen3h4CMjNLKQcAM7OUmuwBYM25LsA5ksZ6p7HOkM56p7HOcBbqPannAMzM7OQmew/AzMxOYtIGAEnXSdoqaZuku851ec4GSXMl/UzSZkkbJX0h2T9N0hOSXk1eO891WSeapIykFyT9ONlOQ52nSvq+pC3Jv/mvTPZ6S/rPyd/2K5K+J6lpMtZZ0gOS9kl6pWLfSesp6ctJ27ZV0sdP93MnZQCQlAHuBz4BLAJukjQxi2ieXwrA70XEQuCDwB1JPe8CnoqIBcBTyfZk8wVgc8V2Gur858BPIuIyYDHl+k/aekuaDfwnYGlEXA5kgJVMzjo/CFw3al/Veib/x1cC70/y/H9JmzdukzIAAMuAbRGxPSKGgIeBFee4TBMuIvZExPPJ+6OUG4TZlOv6UJLsIeAz56SAZ4mkOcD/A/yvit2Tvc4dwEeAvwKIiKGIOMwkrzflL6xslpQFWoDdTMI6R8TTwMFRu09WzxXAwxExGBE7gG2U27xxm6wBYDawq2K7O9k3aUmaB1wJ/ByYERF7oBwkgOnnsGhnw/8L/AFQqtg32ev8XqAH+Otk6Ot/SWplEtc7It4EvgG8AewBjkTET5nEdR7lZPWcsPZtsgYAVdk3aW93ktQGPAJ8MSJ6z3V5ziZJvwbsi4iJXyD1/JYFrgK+GRFXAseYHEMfJ5WMea8A5gOzgFZJv3luS3VemLD2bbIGgG5gbsX2HMpdx0lHUj3lxv87EfGDZPdeSTOT4zOBfeeqfGfBh4FPS9pJeWjvVyX9LZO7zlD+m+6OiJ8n29+nHBAmc73/HbAjInoiIg/8APgQk7vOlU5Wzwlr3yZrAFgHLJA0X1ID5QmTtee4TBNOkiiPCW+OiD+tOLQWuCV5fwvww3e6bGdLRHw5IuZExDzK/67/EBG/ySSuM0BEvAXsknRpsms5sInJXe83gA9Kakn+1pdTnueazHWudLJ6rgVWSmqUNB9YADx7Wp8QEZPyB/gk8AvgNeC/nuvynKU6/mvKXb+XgA3JzyeBCyjfNfBq8jrtXJf1LNX/GuDHyftJX2dgCbA++ff+/4HOyV5v4I+ALcArwN8AjZOxzsD3KM9z5Clf4d96qnoC/zVp27YCnzjdz/WTwGZmKTVZh4DMzGwMDgBmZinlAGBmllIOAGZmKeUAYGaWUg4AZmYp5QBgZpZSDgBmZin1fwFIAwthoYysUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy\n",
    "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('Models/AlphabetSoupCharity2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "This is Attempt #2\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = relu\n",
    "layer3 = 27 : activation function = relu\n",
    "\n",
    "Loss: 0.6051175594329834, Accuracy: 0.7289795875549316\n",
    "\n",
    "A loss value of 60 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "Still not at 75% accuracy. Will try something drastic next.\n",
    "\n",
    "I also ran the following variables through this model:\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.5545361445735565, Accuracy: 0.7241982221603394\n",
    "\n",
    "\n",
    "APPLICATION_TYPE cutoff = 800\n",
    "CLASSIFICATION cutoff = 1000\n",
    "layer1 = 12\n",
    "layer2 = 24\n",
    "layer3 = 36\n",
    "\n",
    "Loss: 0.5560268456039207, Accuracy: 0.7268804907798767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt #3 -- changing the activation functions\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = tanh\n",
    "layer3 = 27 : activation function = tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 9)                 176508    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 18)                180       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 27)                513       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,229\n",
      "Trainable params: 177,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 9\n",
    "hidden_nodes_layer2 = 18\n",
    "hidden_nodes_layer3 = 27\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to convert my y_train variable into a numpy array because of a tensorflow version issue\n",
    "# I also added numpy in the dependencies\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 6s 6ms/step - loss: 0.5095 - accuracy: 0.7510\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.2453 - accuracy: 0.9076\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1599 - accuracy: 0.9370\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1276 - accuracy: 0.9522\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.1036 - accuracy: 0.9596\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0973 - accuracy: 0.9614\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0954 - accuracy: 0.9617\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0941 - accuracy: 0.9613\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0927 - accuracy: 0.9633\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0919 - accuracy: 0.9621\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0910 - accuracy: 0.9629\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0907 - accuracy: 0.9630\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0897 - accuracy: 0.9629\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9612\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0906 - accuracy: 0.9632\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0897 - accuracy: 0.9635\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0890 - accuracy: 0.9630\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0883 - accuracy: 0.9633\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9640\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0874 - accuracy: 0.9642\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0871 - accuracy: 0.9634\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0868 - accuracy: 0.9645\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0873 - accuracy: 0.9638\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0869 - accuracy: 0.9647\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0867 - accuracy: 0.9651\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0864 - accuracy: 0.9651\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0860 - accuracy: 0.9656\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.0859 - accuracy: 0.9655\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0858 - accuracy: 0.9655\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0849 - accuracy: 0.9659\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0847 - accuracy: 0.9665\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0853 - accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0846 - accuracy: 0.9658\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.9656\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0846 - accuracy: 0.9661\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0837 - accuracy: 0.9663\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0841 - accuracy: 0.9665\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0840 - accuracy: 0.9659\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9664\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0836 - accuracy: 0.9664\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0834 - accuracy: 0.9663\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.9659\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.9666\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0830 - accuracy: 0.9663\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0830 - accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0834 - accuracy: 0.9670\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0829 - accuracy: 0.9668\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0825 - accuracy: 0.9669\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9670\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.9669\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.9668\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.9663\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.9665\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9669\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.9670\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0818 - accuracy: 0.9670\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0819 - accuracy: 0.9677\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0814 - accuracy: 0.9672\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.9671\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.9668\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.9675\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0815 - accuracy: 0.9672\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0809 - accuracy: 0.9675\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0813 - accuracy: 0.9674\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0810 - accuracy: 0.9675\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0810 - accuracy: 0.9670\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0808 - accuracy: 0.9673\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0809 - accuracy: 0.9675\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0811 - accuracy: 0.9672\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0809 - accuracy: 0.9673\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9678\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0800 - accuracy: 0.9675\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0808 - accuracy: 0.9672\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.9671\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0811 - accuracy: 0.9668\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.9671\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.9679\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0799 - accuracy: 0.9680\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0805 - accuracy: 0.9673\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.9669\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0813 - accuracy: 0.9671\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0807 - accuracy: 0.9676\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0809 - accuracy: 0.9673\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9673\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.9673\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.9675\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.9673\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0806 - accuracy: 0.9675\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0800 - accuracy: 0.9677\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0801 - accuracy: 0.9678\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0799 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0794 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0797 - accuracy: 0.9678\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.9675\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0806 - accuracy: 0.9677\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.9678\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0793 - accuracy: 0.9679\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.0797 - accuracy: 0.9680\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.0797 - accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "# THIS TAKES AT LEAST THREE AND A HALF MINUTES\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.4860 - accuracy: 0.7645 - 1s/epoch - 4ms/step\n",
      "Loss: 0.4859570264816284, Accuracy: 0.764548122882843\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy\n",
    "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "history_df.plot(y = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('Models/AlphabetSoupCharity3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "This is Attempt #3\n",
    "APPLICATION_TYPE cutoff = 600\n",
    "CLASSIFICATION cutoff = 300\n",
    "layer1 = 9 : activation function = relu\n",
    "layer2 = 18 : activation function = tanh\n",
    "layer3 = 27 : activation function = tanh\n",
    "\n",
    "Loss: 0.4859570264816284, Accuracy: 0.764548122882843\n",
    "\n",
    "A loss value of 48 indicates that the model can be further optimized.\n",
    "The accuracy percent shows that 76% of the model's predicted values align with the true values in the original dataset.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
